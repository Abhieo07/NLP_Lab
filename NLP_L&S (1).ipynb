{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av9Qhj6uwKbg"
      },
      "source": [
        "Name: Gautam Mandal\n",
        "\n",
        "Roll no: 21102A0063\n",
        "\n",
        "CMPN A\n",
        "\n",
        "https://github.com/Abhieo07/NLP_Lab/blob/main/NLP_L%26S%20(1).ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOHqlpRMSc3D"
      },
      "source": [
        "Corpus: The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB5E7WisTDHD"
      },
      "source": [
        "Lemmatization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gNK5yEkTGtD"
      },
      "source": [
        "1) Wordnet Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MBAtmUUhRB",
        "outputId": "0183b06b-34f7-48aa-f44c-bb21e3822c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ---> The\n",
            "Olympics ---> Olympics\n",
            "unite ---> unite\n",
            "nations, ---> nation\n",
            "showcasing ---> showcasing\n",
            "athletic ---> athletic\n",
            "excellence ---> excellence\n",
            "and ---> and\n",
            "fostering ---> fostering\n",
            "global ---> global\n",
            "camaraderie ---> camaraderie\n",
            "through ---> through\n",
            "intense ---> intense\n",
            "competition. ---> competition\n",
            "Olympic ---> Olympic\n",
            "athletes ---> athlete\n",
            "embody ---> embody\n",
            "dedication ---> dedication\n",
            "and ---> and\n",
            "perseverance, ---> perseverance\n",
            "inspiring ---> inspiring\n",
            "millions ---> million\n",
            "with ---> with\n",
            "their ---> their\n",
            "pursuit ---> pursuit\n",
            "of ---> of\n",
            "gold ---> gold\n",
            "medals. ---> medal\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "list_result = text.split()\n",
        "\n",
        "for word in list_result:\n",
        "    word_clean = word.translate(str.maketrans('', '', string.punctuation))\n",
        "    lemmatized_word = wn.lemmatize(word_clean)\n",
        "    print(word + \" ---> \" + lemmatized_word)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyyNZwzpWkSy"
      },
      "source": [
        "2) TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0At9zKBUyvr",
        "outputId": "3c759d98-7c1f-4eab-83b5-4c181f69d155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ---> The\n",
            "Olympics ---> Olympics\n",
            "unite ---> unite\n",
            "nations, ---> nation\n",
            "showcasing ---> showcasing\n",
            "athletic ---> athletic\n",
            "excellence ---> excellence\n",
            "and ---> and\n",
            "fostering ---> fostering\n",
            "global ---> global\n",
            "camaraderie ---> camaraderie\n",
            "through ---> through\n",
            "intense ---> intense\n",
            "competition. ---> competition\n",
            "Olympic ---> Olympic\n",
            "athletes ---> athlete\n",
            "embody ---> embody\n",
            "dedication ---> dedication\n",
            "and ---> and\n",
            "perseverance, ---> perseverance\n",
            "inspiring ---> inspiring\n",
            "millions ---> million\n",
            "with ---> with\n",
            "their ---> their\n",
            "pursuit ---> pursuit\n",
            "of ---> of\n",
            "gold ---> gold\n",
            "medals. ---> medal\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob, Word\n",
        "import string\n",
        "\n",
        "# The input string\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "# Split the string into a list of words\n",
        "list_result = text.split()\n",
        "\n",
        "# Process each word in the list\n",
        "for word in list_result:\n",
        "    # Remove punctuation from the word\n",
        "    word_clean = word.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Lemmatize the cleaned word using TextBlob's Word class\n",
        "    lemmatized_word = Word(word_clean).lemmatize()\n",
        "    # Print the original and lemmatized word\n",
        "    print(word + \" ---> \" + lemmatized_word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaqPv1y3Xewg"
      },
      "source": [
        "3) spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KOM_ReBWl78",
        "outputId": "3bf80f6c-b468-4ac0-db0f-6fa96950f9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ---> the\n",
            "Olympics ---> Olympics\n",
            "unite ---> unite\n",
            "nations ---> nation\n",
            "showcasing ---> showcase\n",
            "athletic ---> athletic\n",
            "excellence ---> excellence\n",
            "and ---> and\n",
            "fostering ---> foster\n",
            "global ---> global\n",
            "camaraderie ---> camaraderie\n",
            "through ---> through\n",
            "intense ---> intense\n",
            "competition ---> competition\n",
            "Olympic ---> olympic\n",
            "athletes ---> athlete\n",
            "embody ---> embody\n",
            "dedication ---> dedication\n",
            "and ---> and\n",
            "perseverance ---> perseverance\n",
            "inspiring ---> inspire\n",
            "millions ---> million\n",
            "with ---> with\n",
            "their ---> their\n",
            "pursuit ---> pursuit\n",
            "of ---> of\n",
            "gold ---> gold\n",
            "medals ---> medal\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model for English\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# The input string\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the original and lemmatized words\n",
        "for token in doc:\n",
        "    if not token.is_punct:  # Skip punctuation\n",
        "        print(token.text + \" ---> \" + token.lemma_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jULhgXsXjGA",
        "outputId": "b301801c-f804-41f3-f4e5-224ef84be4c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the ---> the\n",
            "olympics ---> olympics\n",
            "unite ---> unite\n",
            "nations ---> nation\n",
            "showcasing ---> showcasing\n",
            "athletic ---> athletic\n",
            "excellence ---> excellence\n",
            "and ---> and\n",
            "fostering ---> fostering\n",
            "global ---> global\n",
            "camaraderie ---> camaraderie\n",
            "through ---> through\n",
            "intense ---> intense\n",
            "competition ---> competition\n",
            "olympic ---> olympic\n",
            "athletes ---> athlete\n",
            "embody ---> embody\n",
            "dedication ---> dedication\n",
            "and ---> and\n",
            "perseverance ---> perseverance\n",
            "inspiring ---> inspiring\n",
            "millions ---> million\n",
            "with ---> with\n",
            "their ---> their\n",
            "pursuit ---> pursuit\n",
            "of ---> of\n",
            "gold ---> gold\n",
            "medals ---> medal\n"
          ]
        }
      ],
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "wn = WordNetLemmatizer()\n",
        "\n",
        "# The input string\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "# Simple preprocessing of the text using Gensim's simple_preprocess\n",
        "list_result = simple_preprocess(text)\n",
        "\n",
        "# Lemmatize each word\n",
        "lemmatized_result = []\n",
        "for word in list_result:\n",
        "    lemmatized_word = wn.lemmatize(word)\n",
        "    lemmatized_result.append(lemmatized_word)\n",
        "    print(word + \" ---> \" + lemmatized_word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAPlGGnNdc1l"
      },
      "source": [
        "**Lemmatization**\n",
        "Lemmatization is the process of reducing a word to its base or dictionary form, known as the lemma. Unlike stemming, which might cut off prefixes or suffixes to achieve its goal, lemmatization considers the context and the part of speech (POS) of a word to determine its lemma.\n",
        "\n",
        "Algorithms and Libraries for Lemmatization\n",
        "\n",
        "**WordNetLemmatizer (NLTK):**\n",
        "Algorithm: Uses WordNet, a lexical database for the English language. The WordNetLemmatizer can lemmatize words by looking up their base forms in WordNet and taking into account their POS tags.\n",
        "Python Library: nltk (Natural Language Toolkit)\n",
        "Example Usage: WordNetLemmatizer().lemmatize('running', pos='v') returns 'run'.\n",
        "\n",
        "**TextBlob:**\n",
        "Algorithm: Uses WordNet for lemmatization, similar to NLTKâ€™s WordNetLemmatizer. It also provides a simplified API for lemmatization.\n",
        "Python Library: textblob\n",
        "Example Usage: TextBlob('running').lemmatize('v') returns 'run'.\n",
        "\n",
        "**spaCy:**\n",
        "Algorithm: Uses a more complex, context-aware lemmatization approach as part of its NLP pipeline. It handles lemmatization based on the POS and the context within sentences.\n",
        "Python Library: spacy\n",
        "Example Usage: nlp('running')[0].lemma_ returns 'run'.\n",
        "\n",
        "**Gensim:**\n",
        "Primarily used for topic modeling and vectorization but also includes some preprocessing tools. It doesn't directly provide lemmatization but can use NLTK for it.\n",
        "Installation: pip install gensim\n",
        "Usage: Includes simple_preprocess for tokenization and normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGq3xc0nXoyX",
        "outputId": "4cb7b378-4422-4680-9f26-b3c0085651a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Original Word WordNet Lemma TextBlob Lemma   spaCy Lemma  Gensim Lemma\n",
            "0            the           the            the           the           the\n",
            "1       olympics      olympics       olympics       olympic      olympics\n",
            "2          unite         unite          unite         unite         unite\n",
            "3        nations        nation         nation        nation        nation\n",
            "4     showcasing    showcasing     showcasing      showcase    showcasing\n",
            "5       athletic      athletic       athletic      athletic      athletic\n",
            "6     excellence    excellence     excellence    excellence    excellence\n",
            "7            and           and            and           and           and\n",
            "8      fostering     fostering      fostering        foster     fostering\n",
            "9         global        global         global        global        global\n",
            "10   camaraderie   camaraderie    camaraderie   camaraderie   camaraderie\n",
            "11       through       through        through       through       through\n",
            "12       intense       intense        intense       intense       intense\n",
            "13   competition   competition    competition   competition   competition\n",
            "14       olympic       olympic        olympic       olympic       olympic\n",
            "15      athletes       athlete        athlete       athlete       athlete\n",
            "16        embody        embody         embody        embody        embody\n",
            "17    dedication    dedication     dedication    dedication    dedication\n",
            "18           and           and            and           and           and\n",
            "19  perseverance  perseverance   perseverance  perseverance  perseverance\n",
            "20     inspiring     inspiring      inspiring       inspire     inspiring\n",
            "21      millions       million        million       million       million\n",
            "22          with          with           with          with          with\n",
            "23         their         their          their         their         their\n",
            "24       pursuit       pursuit        pursuit       pursuit       pursuit\n",
            "25            of            of             of            of            of\n",
            "26          gold          gold           gold          gold          gold\n",
            "27        medals         medal          medal         medal         medal\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from textblob import Word as TextBlobWord\n",
        "import spacy\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "list_result = simple_preprocess(text)\n",
        "\n",
        "data = {\n",
        "    'Original Word': [],\n",
        "    'WordNet Lemma': [],\n",
        "    'TextBlob Lemma': [],\n",
        "    'spaCy Lemma': [],\n",
        "    'Gensim Lemma': []\n",
        "}\n",
        "\n",
        "for word in list_result:\n",
        "    word_clean = word.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # WordNet lemmatization\n",
        "    wn_lemma = wn.lemmatize(word_clean)\n",
        "\n",
        "    # TextBlob lemmatization\n",
        "    textblob_lemma = TextBlobWord(word_clean).lemmatize()\n",
        "\n",
        "    # spaCy lemmatization\n",
        "    doc = nlp(word_clean)\n",
        "    spacy_lemma = doc[0].lemma_ if doc else word_clean\n",
        "\n",
        "    # Gensim lemmatization\n",
        "    gensim_lemma = wn.lemmatize(word_clean)\n",
        "\n",
        "    data['Original Word'].append(word)\n",
        "    data['WordNet Lemma'].append(wn_lemma)\n",
        "    data['TextBlob Lemma'].append(textblob_lemma)\n",
        "    data['spaCy Lemma'].append(spacy_lemma)\n",
        "    data['Gensim Lemma'].append(gensim_lemma)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIOfOoi4wJC7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iXLDpVdzIM"
      },
      "source": [
        "**Stemming**\n",
        "Stemming is the process of reducing a word to its root form by removing derivational affixes. Unlike lemmatization, stemming does not consider the context or the POS, which can sometimes result in words that are not actual dictionary words.\n",
        "\n",
        "Algorithms and Libraries for Stemming\n",
        "\n",
        "**Porter Stemmer:**\n",
        "Algorithm: Developed by Martin Porter, this is one of the most widely used stemming algorithms. It applies a series of rules to remove common morphological and inflectional endings from words.\n",
        "Python Library: nltk\n",
        "Example Usage: PorterStemmer().stem('running') returns 'run'.\n",
        "\n",
        "**Lancaster Stemmer:**\n",
        "Algorithm: A more aggressive stemming algorithm compared to Porter. It often trims words more aggressively, which can lead to stems that are more truncated.\n",
        "Python Library: nltk\n",
        "Example Usage: LancasterStemmer().stem('running') returns 'run'.\n",
        "\n",
        "**Regexp Stemmer:**\n",
        "Algorithm: Allows for custom stemming rules based on regular expressions. It can be tailored to specific needs or languages.\n",
        "Python Library: nltk\n",
        "Example Usage: RegexpStemmer('ing$').stem('running') returns 'runn'.\n",
        "\n",
        "**Snowball Stemmer:**\n",
        "Algorithm: An improvement on the Porter Stemmer, also developed by Martin Porter. It includes enhancements and is available for multiple languages.\n",
        "Python Library: nltk\n",
        "Example Usage: SnowballStemmer('english').stem('running') returns 'run'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFe_sogfYcmr",
        "outputId": "1ee9df6b-ced0-4558-c2da-ebd931830df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Original Word Porter Stemmer Lancaster Stemmer Regexp Stemmer  \\\n",
            "0            the            the               the            the   \n",
            "1       olympics          olymp             olymp       olympics   \n",
            "2          unite           unit              unit          unite   \n",
            "3        nations         nation               nat        nations   \n",
            "4     showcasing        showcas           showcas        showcas   \n",
            "5       athletic         athlet            athlet       athletic   \n",
            "6     excellence          excel             excel     excellence   \n",
            "7            and            and               and            and   \n",
            "8      fostering         foster              fost         foster   \n",
            "9         global         global              glob         global   \n",
            "10   camaraderie     camaraderi        camaradery    camaraderie   \n",
            "11       through        through           through        through   \n",
            "12       intense         intens            intens        intense   \n",
            "13   competition       competit          competit    competition   \n",
            "14       olympic          olymp             olymp        olympic   \n",
            "15      athletes         athlet            athlet       athletes   \n",
            "16        embody         embodi            embody         embody   \n",
            "17    dedication          dedic               ded       dication   \n",
            "18           and            and               and            and   \n",
            "19  perseverance       persever            persev   perseverance   \n",
            "20     inspiring         inspir            inspir         inspir   \n",
            "21      millions        million               mil       millions   \n",
            "22          with           with              with           with   \n",
            "23         their          their             their          their   \n",
            "24       pursuit        pursuit           pursuit        pursuit   \n",
            "25            of             of                of             of   \n",
            "26          gold           gold              gold           gold   \n",
            "27        medals          medal               med           mals   \n",
            "\n",
            "   Snowball Stemmer  \n",
            "0               the  \n",
            "1             olymp  \n",
            "2              unit  \n",
            "3            nation  \n",
            "4           showcas  \n",
            "5            athlet  \n",
            "6             excel  \n",
            "7               and  \n",
            "8            foster  \n",
            "9            global  \n",
            "10       camaraderi  \n",
            "11          through  \n",
            "12           intens  \n",
            "13         competit  \n",
            "14            olymp  \n",
            "15           athlet  \n",
            "16           embodi  \n",
            "17            dedic  \n",
            "18              and  \n",
            "19         persever  \n",
            "20           inspir  \n",
            "21          million  \n",
            "22             with  \n",
            "23            their  \n",
            "24          pursuit  \n",
            "25               of  \n",
            "26             gold  \n",
            "27            medal  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "regexp = RegexpStemmer(r'ed|ing$')\n",
        "snowball = SnowballStemmer('english')\n",
        "\n",
        "text = \"The Olympics unite nations, showcasing athletic excellence and fostering global camaraderie through intense competition. Olympic athletes embody dedication and perseverance, inspiring millions with their pursuit of gold medals.\"\n",
        "\n",
        "list_result = simple_preprocess(text)\n",
        "\n",
        "data = {\n",
        "    'Original Word': [],\n",
        "    'Porter Stemmer': [],\n",
        "    'Lancaster Stemmer': [],\n",
        "    'Regexp Stemmer': [],\n",
        "    'Snowball Stemmer': []\n",
        "}\n",
        "\n",
        "for word in list_result:\n",
        "    # Stemming\n",
        "    porter_stem = porter.stem(word)\n",
        "    lancaster_stem = lancaster.stem(word)\n",
        "    regexp_stem = regexp.stem(word)\n",
        "    snowball_stem = snowball.stem(word)\n",
        "\n",
        "    data['Original Word'].append(word)\n",
        "    data['Porter Stemmer'].append(porter_stem)\n",
        "    data['Lancaster Stemmer'].append(lancaster_stem)\n",
        "    data['Regexp Stemmer'].append(regexp_stem)\n",
        "    data['Snowball Stemmer'].append(snowball_stem)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgYqICKVZapd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
